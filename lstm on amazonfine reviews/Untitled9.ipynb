{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Amazon Fine Food Review is about the reviews of customers\n",
    "on the food.</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>LSTM on Amazon Fine Food Review </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = pd.read_csv('D:/ALL learnings/ML/Applied ai/Assinments/lstm on amazonfine reviews/Reviews.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data.isnull().sum()\n",
    "df=project_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before removing score 3: 568454\n",
      "Number of rows after removing score 3: 525814\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows before removing score 3:' + ' ' + str(df['Id'].nunique()))\n",
    "df_score = df[df['Score'] != 3]\n",
    "print('Number of rows after removing score 3:' + ' ' + str(df_score['Id'].nunique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scr(sc):\n",
    "    if sc > 3:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score['Score']=df_score['Score'].apply(scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive (1) and negative (0) reviews\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    443777\n",
       "0     82037\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of positive (1) and negative (0) reviews\")\n",
    "df_score['Score'].value_counts()\n",
    "\n",
    "\n",
    "# imbalanced data bro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data percentage reduced to: 92.4989533014105\n"
     ]
    }
   ],
   "source": [
    "# Check the reduction percentage of data\n",
    "print(\"Data percentage reduced to:\" + ' ' + str(100*(len(df_score['Id'])/len(df['Id']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>B0001PB9FY</td>\n",
       "      <td>A3HDKO7OW0QNK4</td>\n",
       "      <td>Canadian Fan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1107820800</td>\n",
       "      <td>The Best Hot Sauce in the World</td>\n",
       "      <td>I don't know if it's the cactus or the tequila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>575</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>A3PJZ8TU8FDQ1K</td>\n",
       "      <td>Jared Castle</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1231718400</td>\n",
       "      <td>One bite and you'll become a \"chippoisseur\"</td>\n",
       "      <td>I'm addicted to salty and tangy flavors, so wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>2310</td>\n",
       "      <td>B0001VWE0M</td>\n",
       "      <td>AQM74O8Z4FMS0</td>\n",
       "      <td>Sunshine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127606400</td>\n",
       "      <td>Below standard</td>\n",
       "      <td>Too much of the white pith on this orange peel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>2324</td>\n",
       "      <td>B0001VWE0C</td>\n",
       "      <td>AQM74O8Z4FMS0</td>\n",
       "      <td>Sunshine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127606400</td>\n",
       "      <td>Below standard</td>\n",
       "      <td>Too much of the white pith on this orange peel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>2337</td>\n",
       "      <td>B0001FQVCK</td>\n",
       "      <td>A5D06XJHDXK75</td>\n",
       "      <td>C. Po</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1190592000</td>\n",
       "      <td>Baci's are pure heaven - great gift, stocking ...</td>\n",
       "      <td>My family has been in love with Baci's ever si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>2648</td>\n",
       "      <td>B0016FY6H6</td>\n",
       "      <td>A2NLZ3M0OJV9NX</td>\n",
       "      <td>Mark Bodzin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1313107200</td>\n",
       "      <td>way too weak for my tastes</td>\n",
       "      <td>What can i say, I love iced tea. I drink a lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>2654</td>\n",
       "      <td>B0016FY6H6</td>\n",
       "      <td>A3I4PCBRENJNG2</td>\n",
       "      <td>L. Cain</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1300579200</td>\n",
       "      <td>quality lightly sweetened green tea powder</td>\n",
       "      <td>lots of uses for this green tea...&lt;br /&gt;&lt;br /&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>2947</td>\n",
       "      <td>B0002TJAZK</td>\n",
       "      <td>A2ISKAWUPGGOLZ</td>\n",
       "      <td>M. S. Handley</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1310774400</td>\n",
       "      <td>Kitty Junk Food</td>\n",
       "      <td>We have five cats - one an elderly cat of 15 y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>2948</td>\n",
       "      <td>B0002TJAZK</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>3886</td>\n",
       "      <td>B005GX7GVW</td>\n",
       "      <td>AS1FCKNKY95ID</td>\n",
       "      <td>Juli A. Lee \"JingleJL\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1336953600</td>\n",
       "      <td>Great and good price!</td>\n",
       "      <td>I love these noodles.  They are really great f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3886</th>\n",
       "      <td>3887</td>\n",
       "      <td>B005GX7GVW</td>\n",
       "      <td>A1I34N9LFOSCX7</td>\n",
       "      <td>Smeggy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1349136000</td>\n",
       "      <td>Yum!</td>\n",
       "      <td>This soup cooks up quickly and is very yummy! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>4641</td>\n",
       "      <td>B0002NYO9I</td>\n",
       "      <td>A5DVX3B075B09</td>\n",
       "      <td>Patricia Kays</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1338940800</td>\n",
       "      <td>LOVELY JUNIPER BERRIES</td>\n",
       "      <td>Dried berries, still with texture and the quin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>4642</td>\n",
       "      <td>B0002NYO9I</td>\n",
       "      <td>A376TWN7I4HMZ8</td>\n",
       "      <td>helios</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1324252800</td>\n",
       "      <td>Exaclty what i ordered</td>\n",
       "      <td>Again, exactly what I ordered. No fuss, no mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>5398</td>\n",
       "      <td>B00622CYVS</td>\n",
       "      <td>ATIHDHZYNQ0EI</td>\n",
       "      <td>Kristen O'donnell \"twinsmom\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1270425600</td>\n",
       "      <td>Organic and Tasty</td>\n",
       "      <td>I'd continue to buy but I'm moving over to mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5451</th>\n",
       "      <td>5452</td>\n",
       "      <td>B00622CYVI</td>\n",
       "      <td>ATIHDHZYNQ0EI</td>\n",
       "      <td>Kristen O'donnell \"twinsmom\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1270425600</td>\n",
       "      <td>Organic and Tasty</td>\n",
       "      <td>I'd continue to buy but I'm moving over to mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5463</th>\n",
       "      <td>5464</td>\n",
       "      <td>B00622CYVI</td>\n",
       "      <td>A2ETT9SL9AN39O</td>\n",
       "      <td>Danielle L Bostic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1333324800</td>\n",
       "      <td>Great Product</td>\n",
       "      <td>My one year old loves this product. She eats o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476</th>\n",
       "      <td>5477</td>\n",
       "      <td>B00622CYVI</td>\n",
       "      <td>A2MF0C4E7GYCI</td>\n",
       "      <td>VW \"VW\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1298678400</td>\n",
       "      <td>My child loves this food!</td>\n",
       "      <td>Great value if you buy it as a subscribe and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5488</th>\n",
       "      <td>5489</td>\n",
       "      <td>B00622CYVI</td>\n",
       "      <td>ASEAKR59G0SLT</td>\n",
       "      <td>Reviewer \"Jason\"</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Product is good; Amazon fulfillment is poor</td>\n",
       "      <td>Amazon normally does a fantastic job getting p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5603</th>\n",
       "      <td>5604</td>\n",
       "      <td>B000G1X45G</td>\n",
       "      <td>A36HK6V63C02XE</td>\n",
       "      <td>Renee \"supermom\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1236556800</td>\n",
       "      <td>If you love strong full flavored coffee---this...</td>\n",
       "      <td>If you like strong coffee, this is it!  The fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5958</th>\n",
       "      <td>5959</td>\n",
       "      <td>B001O2IX8E</td>\n",
       "      <td>A3KDZCQ82JFWLN</td>\n",
       "      <td>Phoebe Oh</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1245888000</td>\n",
       "      <td>Some broken jars</td>\n",
       "      <td>When I saw some of the Earth's Best jars offer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6441</th>\n",
       "      <td>6442</td>\n",
       "      <td>B000QB0WUG</td>\n",
       "      <td>A16TI8YVRRC8AN</td>\n",
       "      <td>M. Vega</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1329868800</td>\n",
       "      <td>Yummy</td>\n",
       "      <td>Tried this in a turkey burger and it was sooo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>6518</td>\n",
       "      <td>B005O8BLLU</td>\n",
       "      <td>APH7I7OZ8WUJP</td>\n",
       "      <td>J. Simpson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1347494400</td>\n",
       "      <td>Great first food</td>\n",
       "      <td>This is excellent for a baby's first taste. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7321</th>\n",
       "      <td>7322</td>\n",
       "      <td>B0042395CA</td>\n",
       "      <td>AKZKG2Z7CNV27</td>\n",
       "      <td>BreezyPaige</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1332547200</td>\n",
       "      <td>Decent, but not great</td>\n",
       "      <td>When I first started to use IAMS Savory Sauce,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7899</th>\n",
       "      <td>7900</td>\n",
       "      <td>B00126EQ8I</td>\n",
       "      <td>A3O646NL6SH3ZL</td>\n",
       "      <td>J McCool</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1255392000</td>\n",
       "      <td>The real deal (ALMOST)</td>\n",
       "      <td>I pass around favorable endorsements very seld...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7904</th>\n",
       "      <td>7905</td>\n",
       "      <td>B00285FFCS</td>\n",
       "      <td>ARXORJX86X1J2</td>\n",
       "      <td>Yvette Mendoza</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1327017600</td>\n",
       "      <td>Chocolate heaven</td>\n",
       "      <td>My mother and father were the recipient of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>8763</td>\n",
       "      <td>B004OLUCAE</td>\n",
       "      <td>A281NPSIMI1C2R</td>\n",
       "      <td>Rebecca of Amazon \"The Rebecca Review\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1316131200</td>\n",
       "      <td>Delicious Alternative to Sugar</td>\n",
       "      <td>If you are looking for a sweetener that is del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8993</th>\n",
       "      <td>8994</td>\n",
       "      <td>B006N3IG4K</td>\n",
       "      <td>A5U24IWH64IFF</td>\n",
       "      <td>Kimdoll</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1302480000</td>\n",
       "      <td>Absolutely delicious coffee!</td>\n",
       "      <td>I am a huge coffee drinker, and love the k-cup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>8995</td>\n",
       "      <td>B006N3IG4K</td>\n",
       "      <td>A1RVCWFP3SC3GU</td>\n",
       "      <td>Cakediva</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1300233600</td>\n",
       "      <td>YUMMY</td>\n",
       "      <td>We always drink Timmothy's or Emeril's. Though...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>8996</td>\n",
       "      <td>B006N3IG4K</td>\n",
       "      <td>A12SO47JRQGUPR</td>\n",
       "      <td>Thomas Smith \"tjaye\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1299801600</td>\n",
       "      <td>Good Stuff</td>\n",
       "      <td>Good subtle flavored coffee for the mid-aftern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>8997</td>\n",
       "      <td>B006N3IG4K</td>\n",
       "      <td>A86RUZGD22FDR</td>\n",
       "      <td>Another coffee drinker</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1299110400</td>\n",
       "      <td>Delivers what was promises</td>\n",
       "      <td>Wolfgang Puck's Chef's Reserve Colombian (Dark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568323</th>\n",
       "      <td>568324</td>\n",
       "      <td>B0013Z0PTW</td>\n",
       "      <td>A18AAABCIJKC5Q</td>\n",
       "      <td>Rhiever</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1295740800</td>\n",
       "      <td>High fiber isn't necessarily a good thing!</td>\n",
       "      <td>I recently cut fiber one bars out of my diet a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568351</th>\n",
       "      <td>568352</td>\n",
       "      <td>B003O5Q3KE</td>\n",
       "      <td>A2T26HRHG8172X</td>\n",
       "      <td>pompoodlejr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1293321600</td>\n",
       "      <td>dog treats</td>\n",
       "      <td>i have 4 dogs, 3 of them love these peanut but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568352</th>\n",
       "      <td>568353</td>\n",
       "      <td>B003O5Q3KE</td>\n",
       "      <td>A3J8TD7DX73JK0</td>\n",
       "      <td>Joni</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1292198400</td>\n",
       "      <td>Repeat Purchaser - My dogs love these</td>\n",
       "      <td>I order several of these everytime I place an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568353</th>\n",
       "      <td>568354</td>\n",
       "      <td>B003O5Q3KE</td>\n",
       "      <td>A2U4L18LOGSHQ1</td>\n",
       "      <td>Larry L. Wieskamp \"larwie\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1291161600</td>\n",
       "      <td>doggy crackers</td>\n",
       "      <td>These were kind of expensive for a dog treat a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568354</th>\n",
       "      <td>568355</td>\n",
       "      <td>B003O5Q3KE</td>\n",
       "      <td>A2Q833MV8UEM37</td>\n",
       "      <td>Josh Crick</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1286841600</td>\n",
       "      <td>My Dog HATED these treats</td>\n",
       "      <td>Went into the dumpster the very first night. M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568361</th>\n",
       "      <td>568362</td>\n",
       "      <td>B000LKVRQA</td>\n",
       "      <td>A1YUL9PCJR3JTY</td>\n",
       "      <td>O. Brown \"Ms. O. Khannah-Brown\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1282608000</td>\n",
       "      <td>An Earl Grey Tea That Won't Disappoint</td>\n",
       "      <td>*****&lt;br /&gt;St. Dalfour's wonderful Certified O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568370</th>\n",
       "      <td>568371</td>\n",
       "      <td>B003NQMPYM</td>\n",
       "      <td>A26EL6HQW6SJZ4</td>\n",
       "      <td>Michael Larson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1328313600</td>\n",
       "      <td>M. Larson</td>\n",
       "      <td>We tried these \"candy bars\" in Hawaii.  They a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568386</th>\n",
       "      <td>568387</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A1U36T07L3HM0E</td>\n",
       "      <td>F. Dias</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1256688000</td>\n",
       "      <td>Just some info to help...</td>\n",
       "      <td>Just FYI, I checked the nutritional informatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568387</th>\n",
       "      <td>568388</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A3NL4VV8FXZ266</td>\n",
       "      <td>Ruby \"Tuesday\"</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1187395200</td>\n",
       "      <td>good idea but messy</td>\n",
       "      <td>this ia a good idea; however, difficult to ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568388</th>\n",
       "      <td>568389</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A3JDX65QJO3Q2F</td>\n",
       "      <td>Don't believe it just because someone told yo...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1187395200</td>\n",
       "      <td>Awesome product</td>\n",
       "      <td>I have used agave for many things and find tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568389</th>\n",
       "      <td>568390</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A2LGOMSYQJ5PZS</td>\n",
       "      <td>N. Hjort</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1257552000</td>\n",
       "      <td>great flavor</td>\n",
       "      <td>The cinnamon honey sticks flavor was excellent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568390</th>\n",
       "      <td>568391</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A3HRWZW3ZK6W49</td>\n",
       "      <td>Kristen McDaniel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1239148800</td>\n",
       "      <td>Yummy honey in a convenient portion.</td>\n",
       "      <td>I bought this in an effort to help myself quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568391</th>\n",
       "      <td>568392</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A31YNKI4TS6ZJW</td>\n",
       "      <td>Lauren L.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1234310400</td>\n",
       "      <td>convenient way of taking your agave with you!</td>\n",
       "      <td>I was hesitant about this product based on som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568392</th>\n",
       "      <td>568393</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A1XDASQ60YMQLN</td>\n",
       "      <td>Karen Pratt \"tudie\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1207526400</td>\n",
       "      <td>Wonderful Flavor</td>\n",
       "      <td>These little goodies are so full of flavor and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568393</th>\n",
       "      <td>568394</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>AJGGU9YEZNPY7</td>\n",
       "      <td>Kah-tay</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1327795200</td>\n",
       "      <td>Sweet DEAL!</td>\n",
       "      <td>These are great to have!  I toss one in my dau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568395</th>\n",
       "      <td>568396</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A2NEOGFAJDJMFV</td>\n",
       "      <td>SUZANNE L. ARASIM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1279411200</td>\n",
       "      <td>Very handy, yummy too</td>\n",
       "      <td>My mom-in-law had rec'd 1 box of these in a gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568396</th>\n",
       "      <td>568397</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A27OFOL5ERMRWE</td>\n",
       "      <td>Mary A. Simpson \"Boatlady13\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1236729600</td>\n",
       "      <td>Lemon Honey Sticks</td>\n",
       "      <td>These honey sticks are so nice in a cup of tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568397</th>\n",
       "      <td>568398</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>AWLK6NSSV0YNA</td>\n",
       "      <td>Midwest Mommy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1219363200</td>\n",
       "      <td>Sweet Treat!</td>\n",
       "      <td>These Chai Honey Sticks are SO good!  I enjoy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568398</th>\n",
       "      <td>568399</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>AU5C3IYBH9JCW</td>\n",
       "      <td>S. Musicant \"Bermusicant\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1216512000</td>\n",
       "      <td>Portable Health</td>\n",
       "      <td>I agree with other reviewers about Agave in ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568399</th>\n",
       "      <td>568400</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A339H0D2F669XI</td>\n",
       "      <td>C. Nicholls</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1208217600</td>\n",
       "      <td>honey sticks</td>\n",
       "      <td>These are straws filled with lemon flavored ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568400</th>\n",
       "      <td>568401</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A3AIZS4BZXUKIP</td>\n",
       "      <td>Shirley Watt \"gmaof7\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1202428800</td>\n",
       "      <td>Great for traveling or eating out!</td>\n",
       "      <td>These are GREAT for carrying in my purse for e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568402</th>\n",
       "      <td>568403</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A1A3H22VVZYUKW</td>\n",
       "      <td>msfreixy</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1187049600</td>\n",
       "      <td>alternative sweetner</td>\n",
       "      <td>I was disappointed in this product, as I had r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568403</th>\n",
       "      <td>568404</td>\n",
       "      <td>B001EQ5O6Y</td>\n",
       "      <td>A2891E3BMAKGYN</td>\n",
       "      <td>PCNiles \"reader/writer\"</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1264118400</td>\n",
       "      <td>Deceptive Term = \"Sticks\"</td>\n",
       "      <td>When I ordered these, based on the description...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568407</th>\n",
       "      <td>568408</td>\n",
       "      <td>B0018CLWM4</td>\n",
       "      <td>ANKM1RMQ4RKQ6</td>\n",
       "      <td>Spaceman</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Premium Edge Dry Cat Food for Kitten</td>\n",
       "      <td>My 6 month old male Tuxedo cat likes Premium E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568408</th>\n",
       "      <td>568409</td>\n",
       "      <td>B0018CLWM4</td>\n",
       "      <td>AJGOF4W50ZNB4</td>\n",
       "      <td>je2u</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1310515200</td>\n",
       "      <td>Premium Edge Kitten Food</td>\n",
       "      <td>This is a good food with decent ingredients &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568409</th>\n",
       "      <td>568410</td>\n",
       "      <td>B0018CLWM4</td>\n",
       "      <td>A2PE0AGWV6OPL7</td>\n",
       "      <td>Dark Water Mermaid</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1309651200</td>\n",
       "      <td>Quality &amp; affordable food</td>\n",
       "      <td>I was very pleased with the ingredient quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568410</th>\n",
       "      <td>568411</td>\n",
       "      <td>B0018CLWM4</td>\n",
       "      <td>A88HLWDCU57WG</td>\n",
       "      <td>R28</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1332979200</td>\n",
       "      <td>litter box</td>\n",
       "      <td>My main reason for the five star review has to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568411</th>\n",
       "      <td>568412</td>\n",
       "      <td>B0018CLWM4</td>\n",
       "      <td>AUX1HSY8FX55S</td>\n",
       "      <td>DAW</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1319500800</td>\n",
       "      <td>Happy Camper</td>\n",
       "      <td>I bought this to try on two registered Maine C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568412</th>\n",
       "      <td>568413</td>\n",
       "      <td>B0018CLWM4</td>\n",
       "      <td>AVZ2OZ479Q9E8</td>\n",
       "      <td>Ai Ling Chow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1336435200</td>\n",
       "      <td>Two Siberians like it!</td>\n",
       "      <td>When we brought home two 3-month-old purebred ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568413</th>\n",
       "      <td>568414</td>\n",
       "      <td>B0018CLWM4</td>\n",
       "      <td>AI3Y26HLPYW4L</td>\n",
       "      <td>kimosabe</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1330041600</td>\n",
       "      <td>premium edge cat food</td>\n",
       "      <td>My cats don't like it. what else can I say to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161949 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId  \\\n",
       "29          30  B0001PB9FY  A3HDKO7OW0QNK4   \n",
       "574        575  B000G6RYNE  A3PJZ8TU8FDQ1K   \n",
       "2309      2310  B0001VWE0M   AQM74O8Z4FMS0   \n",
       "2323      2324  B0001VWE0C   AQM74O8Z4FMS0   \n",
       "2336      2337  B0001FQVCK   A5D06XJHDXK75   \n",
       "2647      2648  B0016FY6H6  A2NLZ3M0OJV9NX   \n",
       "2653      2654  B0016FY6H6  A3I4PCBRENJNG2   \n",
       "2946      2947  B0002TJAZK  A2ISKAWUPGGOLZ   \n",
       "2947      2948  B0002TJAZK  A3TVZM3ZIXG8YW   \n",
       "3885      3886  B005GX7GVW   AS1FCKNKY95ID   \n",
       "3886      3887  B005GX7GVW  A1I34N9LFOSCX7   \n",
       "4640      4641  B0002NYO9I   A5DVX3B075B09   \n",
       "4641      4642  B0002NYO9I  A376TWN7I4HMZ8   \n",
       "5397      5398  B00622CYVS   ATIHDHZYNQ0EI   \n",
       "5451      5452  B00622CYVI   ATIHDHZYNQ0EI   \n",
       "5463      5464  B00622CYVI  A2ETT9SL9AN39O   \n",
       "5476      5477  B00622CYVI   A2MF0C4E7GYCI   \n",
       "5488      5489  B00622CYVI   ASEAKR59G0SLT   \n",
       "5603      5604  B000G1X45G  A36HK6V63C02XE   \n",
       "5958      5959  B001O2IX8E  A3KDZCQ82JFWLN   \n",
       "6441      6442  B000QB0WUG  A16TI8YVRRC8AN   \n",
       "6517      6518  B005O8BLLU   APH7I7OZ8WUJP   \n",
       "7321      7322  B0042395CA   AKZKG2Z7CNV27   \n",
       "7899      7900  B00126EQ8I  A3O646NL6SH3ZL   \n",
       "7904      7905  B00285FFCS   ARXORJX86X1J2   \n",
       "8762      8763  B004OLUCAE  A281NPSIMI1C2R   \n",
       "8993      8994  B006N3IG4K   A5U24IWH64IFF   \n",
       "8994      8995  B006N3IG4K  A1RVCWFP3SC3GU   \n",
       "8995      8996  B006N3IG4K  A12SO47JRQGUPR   \n",
       "8996      8997  B006N3IG4K   A86RUZGD22FDR   \n",
       "...        ...         ...             ...   \n",
       "568323  568324  B0013Z0PTW  A18AAABCIJKC5Q   \n",
       "568351  568352  B003O5Q3KE  A2T26HRHG8172X   \n",
       "568352  568353  B003O5Q3KE  A3J8TD7DX73JK0   \n",
       "568353  568354  B003O5Q3KE  A2U4L18LOGSHQ1   \n",
       "568354  568355  B003O5Q3KE  A2Q833MV8UEM37   \n",
       "568361  568362  B000LKVRQA  A1YUL9PCJR3JTY   \n",
       "568370  568371  B003NQMPYM  A26EL6HQW6SJZ4   \n",
       "568386  568387  B001EQ5O6Y  A1U36T07L3HM0E   \n",
       "568387  568388  B001EQ5O6Y  A3NL4VV8FXZ266   \n",
       "568388  568389  B001EQ5O6Y  A3JDX65QJO3Q2F   \n",
       "568389  568390  B001EQ5O6Y  A2LGOMSYQJ5PZS   \n",
       "568390  568391  B001EQ5O6Y  A3HRWZW3ZK6W49   \n",
       "568391  568392  B001EQ5O6Y  A31YNKI4TS6ZJW   \n",
       "568392  568393  B001EQ5O6Y  A1XDASQ60YMQLN   \n",
       "568393  568394  B001EQ5O6Y   AJGGU9YEZNPY7   \n",
       "568395  568396  B001EQ5O6Y  A2NEOGFAJDJMFV   \n",
       "568396  568397  B001EQ5O6Y  A27OFOL5ERMRWE   \n",
       "568397  568398  B001EQ5O6Y   AWLK6NSSV0YNA   \n",
       "568398  568399  B001EQ5O6Y   AU5C3IYBH9JCW   \n",
       "568399  568400  B001EQ5O6Y  A339H0D2F669XI   \n",
       "568400  568401  B001EQ5O6Y  A3AIZS4BZXUKIP   \n",
       "568402  568403  B001EQ5O6Y  A1A3H22VVZYUKW   \n",
       "568403  568404  B001EQ5O6Y  A2891E3BMAKGYN   \n",
       "568407  568408  B0018CLWM4   ANKM1RMQ4RKQ6   \n",
       "568408  568409  B0018CLWM4   AJGOF4W50ZNB4   \n",
       "568409  568410  B0018CLWM4  A2PE0AGWV6OPL7   \n",
       "568410  568411  B0018CLWM4   A88HLWDCU57WG   \n",
       "568411  568412  B0018CLWM4   AUX1HSY8FX55S   \n",
       "568412  568413  B0018CLWM4   AVZ2OZ479Q9E8   \n",
       "568413  568414  B0018CLWM4   AI3Y26HLPYW4L   \n",
       "\n",
       "                                             ProfileName  \\\n",
       "29                                          Canadian Fan   \n",
       "574                                         Jared Castle   \n",
       "2309                                            Sunshine   \n",
       "2323                                            Sunshine   \n",
       "2336                                               C. Po   \n",
       "2647                                         Mark Bodzin   \n",
       "2653                                             L. Cain   \n",
       "2946                                       M. S. Handley   \n",
       "2947                                   christopher hayes   \n",
       "3885                              Juli A. Lee \"JingleJL\"   \n",
       "3886                                              Smeggy   \n",
       "4640                                       Patricia Kays   \n",
       "4641                                              helios   \n",
       "5397                        Kristen O'donnell \"twinsmom\"   \n",
       "5451                        Kristen O'donnell \"twinsmom\"   \n",
       "5463                                   Danielle L Bostic   \n",
       "5476                                             VW \"VW\"   \n",
       "5488                                    Reviewer \"Jason\"   \n",
       "5603                                    Renee \"supermom\"   \n",
       "5958                                           Phoebe Oh   \n",
       "6441                                             M. Vega   \n",
       "6517                                          J. Simpson   \n",
       "7321                                         BreezyPaige   \n",
       "7899                                            J McCool   \n",
       "7904                                      Yvette Mendoza   \n",
       "8762              Rebecca of Amazon \"The Rebecca Review\"   \n",
       "8993                                             Kimdoll   \n",
       "8994                                            Cakediva   \n",
       "8995                                Thomas Smith \"tjaye\"   \n",
       "8996                              Another coffee drinker   \n",
       "...                                                  ...   \n",
       "568323                                           Rhiever   \n",
       "568351                                       pompoodlejr   \n",
       "568352                                              Joni   \n",
       "568353                        Larry L. Wieskamp \"larwie\"   \n",
       "568354                                        Josh Crick   \n",
       "568361                   O. Brown \"Ms. O. Khannah-Brown\"   \n",
       "568370                                    Michael Larson   \n",
       "568386                                           F. Dias   \n",
       "568387                                    Ruby \"Tuesday\"   \n",
       "568388  Don't believe it just because someone told yo...   \n",
       "568389                                          N. Hjort   \n",
       "568390                                  Kristen McDaniel   \n",
       "568391                                         Lauren L.   \n",
       "568392                               Karen Pratt \"tudie\"   \n",
       "568393                                           Kah-tay   \n",
       "568395                                 SUZANNE L. ARASIM   \n",
       "568396                      Mary A. Simpson \"Boatlady13\"   \n",
       "568397                                     Midwest Mommy   \n",
       "568398                         S. Musicant \"Bermusicant\"   \n",
       "568399                                       C. Nicholls   \n",
       "568400                             Shirley Watt \"gmaof7\"   \n",
       "568402                                          msfreixy   \n",
       "568403                           PCNiles \"reader/writer\"   \n",
       "568407                                          Spaceman   \n",
       "568408                                              je2u   \n",
       "568409                                Dark Water Mermaid   \n",
       "568410                                               R28   \n",
       "568411                                               DAW   \n",
       "568412                                      Ai Ling Chow   \n",
       "568413                                          kimosabe   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "29                         1                       1      1  1107820800   \n",
       "574                        2                       2      1  1231718400   \n",
       "2309                       0                       0      0  1127606400   \n",
       "2323                       0                       0      0  1127606400   \n",
       "2336                       1                       1      1  1190592000   \n",
       "2647                       0                       0      0  1313107200   \n",
       "2653                       0                       0      1  1300579200   \n",
       "2946                       0                       1      0  1310774400   \n",
       "2947                       0                       2      0  1291420800   \n",
       "3885                       1                       1      1  1336953600   \n",
       "3886                       0                       0      1  1349136000   \n",
       "4640                       0                       0      1  1338940800   \n",
       "4641                       0                       1      1  1324252800   \n",
       "5397                       1                       1      1  1270425600   \n",
       "5451                       2                       2      1  1270425600   \n",
       "5463                       0                       0      1  1333324800   \n",
       "5476                       0                       0      1  1298678400   \n",
       "5488                       1                       3      0  1329782400   \n",
       "5603                       0                       0      1  1236556800   \n",
       "5958                       0                       1      0  1245888000   \n",
       "6441                       0                       0      1  1329868800   \n",
       "6517                       0                       0      1  1347494400   \n",
       "7321                       0                       0      0  1332547200   \n",
       "7899                       1                       1      1  1255392000   \n",
       "7904                       0                       0      1  1327017600   \n",
       "8762                       0                       0      1  1316131200   \n",
       "8993                       1                       1      1  1302480000   \n",
       "8994                       1                       1      1  1300233600   \n",
       "8995                       1                       1      1  1299801600   \n",
       "8996                       1                       1      1  1299110400   \n",
       "...                      ...                     ...    ...         ...   \n",
       "568323                     1                       3      0  1295740800   \n",
       "568351                     0                       0      1  1293321600   \n",
       "568352                     0                       0      1  1292198400   \n",
       "568353                     0                       0      0  1291161600   \n",
       "568354                     0                       2      0  1286841600   \n",
       "568361                     1                       1      1  1282608000   \n",
       "568370                     0                       0      1  1328313600   \n",
       "568386                     7                       7      1  1256688000   \n",
       "568387                     3                       3      0  1187395200   \n",
       "568388                     5                       6      1  1187395200   \n",
       "568389                     2                       2      1  1257552000   \n",
       "568390                     1                       1      1  1239148800   \n",
       "568391                     1                       1      1  1234310400   \n",
       "568392                     1                       1      1  1207526400   \n",
       "568393                     0                       0      1  1327795200   \n",
       "568395                     0                       0      1  1279411200   \n",
       "568396                     0                       0      1  1236729600   \n",
       "568397                     0                       0      1  1219363200   \n",
       "568398                     0                       0      1  1216512000   \n",
       "568399                     0                       0      1  1208217600   \n",
       "568400                     0                       0      1  1202428800   \n",
       "568402                     1                       3      0  1187049600   \n",
       "568403                     0                       6      0  1264118400   \n",
       "568407                     6                       6      1  1291420800   \n",
       "568408                     3                       3      1  1310515200   \n",
       "568409                     3                       3      1  1309651200   \n",
       "568410                     2                       2      1  1332979200   \n",
       "568411                     1                       1      1  1319500800   \n",
       "568412                     0                       0      1  1336435200   \n",
       "568413                     1                       2      0  1330041600   \n",
       "\n",
       "                                                  Summary  \\\n",
       "29                        The Best Hot Sauce in the World   \n",
       "574           One bite and you'll become a \"chippoisseur\"   \n",
       "2309                                       Below standard   \n",
       "2323                                       Below standard   \n",
       "2336    Baci's are pure heaven - great gift, stocking ...   \n",
       "2647                           way too weak for my tastes   \n",
       "2653           quality lightly sweetened green tea powder   \n",
       "2946                                      Kitty Junk Food   \n",
       "2947    Filler food is empty, leaves your cat always n...   \n",
       "3885                                Great and good price!   \n",
       "3886                                                 Yum!   \n",
       "4640                               LOVELY JUNIPER BERRIES   \n",
       "4641                               Exaclty what i ordered   \n",
       "5397                                    Organic and Tasty   \n",
       "5451                                    Organic and Tasty   \n",
       "5463                                        Great Product   \n",
       "5476                            My child loves this food!   \n",
       "5488          Product is good; Amazon fulfillment is poor   \n",
       "5603    If you love strong full flavored coffee---this...   \n",
       "5958                                     Some broken jars   \n",
       "6441                                                Yummy   \n",
       "6517                                     Great first food   \n",
       "7321                                Decent, but not great   \n",
       "7899                               The real deal (ALMOST)   \n",
       "7904                                     Chocolate heaven   \n",
       "8762                       Delicious Alternative to Sugar   \n",
       "8993                         Absolutely delicious coffee!   \n",
       "8994                                                YUMMY   \n",
       "8995                                           Good Stuff   \n",
       "8996                           Delivers what was promises   \n",
       "...                                                   ...   \n",
       "568323         High fiber isn't necessarily a good thing!   \n",
       "568351                                         dog treats   \n",
       "568352              Repeat Purchaser - My dogs love these   \n",
       "568353                                     doggy crackers   \n",
       "568354                          My Dog HATED these treats   \n",
       "568361             An Earl Grey Tea That Won't Disappoint   \n",
       "568370                                          M. Larson   \n",
       "568386                          Just some info to help...   \n",
       "568387                                good idea but messy   \n",
       "568388                                    Awesome product   \n",
       "568389                                       great flavor   \n",
       "568390               Yummy honey in a convenient portion.   \n",
       "568391      convenient way of taking your agave with you!   \n",
       "568392                                   Wonderful Flavor   \n",
       "568393                                        Sweet DEAL!   \n",
       "568395                              Very handy, yummy too   \n",
       "568396                                 Lemon Honey Sticks   \n",
       "568397                                       Sweet Treat!   \n",
       "568398                                    Portable Health   \n",
       "568399                                       honey sticks   \n",
       "568400                 Great for traveling or eating out!   \n",
       "568402                               alternative sweetner   \n",
       "568403                          Deceptive Term = \"Sticks\"   \n",
       "568407               Premium Edge Dry Cat Food for Kitten   \n",
       "568408                           Premium Edge Kitten Food   \n",
       "568409                          Quality & affordable food   \n",
       "568410                                         litter box   \n",
       "568411                                       Happy Camper   \n",
       "568412                             Two Siberians like it!   \n",
       "568413                              premium edge cat food   \n",
       "\n",
       "                                                     Text  \n",
       "29      I don't know if it's the cactus or the tequila...  \n",
       "574     I'm addicted to salty and tangy flavors, so wh...  \n",
       "2309    Too much of the white pith on this orange peel...  \n",
       "2323    Too much of the white pith on this orange peel...  \n",
       "2336    My family has been in love with Baci's ever si...  \n",
       "2647    What can i say, I love iced tea. I drink a lot...  \n",
       "2653    lots of uses for this green tea...<br /><br />...  \n",
       "2946    We have five cats - one an elderly cat of 15 y...  \n",
       "2947    This review will make me sound really stupid, ...  \n",
       "3885    I love these noodles.  They are really great f...  \n",
       "3886    This soup cooks up quickly and is very yummy! ...  \n",
       "4640    Dried berries, still with texture and the quin...  \n",
       "4641    Again, exactly what I ordered. No fuss, no mus...  \n",
       "5397    I'd continue to buy but I'm moving over to mor...  \n",
       "5451    I'd continue to buy but I'm moving over to mor...  \n",
       "5463    My one year old loves this product. She eats o...  \n",
       "5476    Great value if you buy it as a subscribe and s...  \n",
       "5488    Amazon normally does a fantastic job getting p...  \n",
       "5603    If you like strong coffee, this is it!  The fl...  \n",
       "5958    When I saw some of the Earth's Best jars offer...  \n",
       "6441    Tried this in a turkey burger and it was sooo ...  \n",
       "6517    This is excellent for a baby's first taste. Th...  \n",
       "7321    When I first started to use IAMS Savory Sauce,...  \n",
       "7899    I pass around favorable endorsements very seld...  \n",
       "7904    My mother and father were the recipient of the...  \n",
       "8762    If you are looking for a sweetener that is del...  \n",
       "8993    I am a huge coffee drinker, and love the k-cup...  \n",
       "8994    We always drink Timmothy's or Emeril's. Though...  \n",
       "8995    Good subtle flavored coffee for the mid-aftern...  \n",
       "8996    Wolfgang Puck's Chef's Reserve Colombian (Dark...  \n",
       "...                                                   ...  \n",
       "568323  I recently cut fiber one bars out of my diet a...  \n",
       "568351  i have 4 dogs, 3 of them love these peanut but...  \n",
       "568352  I order several of these everytime I place an ...  \n",
       "568353  These were kind of expensive for a dog treat a...  \n",
       "568354  Went into the dumpster the very first night. M...  \n",
       "568361  *****<br />St. Dalfour's wonderful Certified O...  \n",
       "568370  We tried these \"candy bars\" in Hawaii.  They a...  \n",
       "568386  Just FYI, I checked the nutritional informatio...  \n",
       "568387  this ia a good idea; however, difficult to ope...  \n",
       "568388  I have used agave for many things and find tha...  \n",
       "568389  The cinnamon honey sticks flavor was excellent...  \n",
       "568390  I bought this in an effort to help myself quit...  \n",
       "568391  I was hesitant about this product based on som...  \n",
       "568392  These little goodies are so full of flavor and...  \n",
       "568393  These are great to have!  I toss one in my dau...  \n",
       "568395  My mom-in-law had rec'd 1 box of these in a gi...  \n",
       "568396  These honey sticks are so nice in a cup of tea...  \n",
       "568397  These Chai Honey Sticks are SO good!  I enjoy ...  \n",
       "568398  I agree with other reviewers about Agave in ge...  \n",
       "568399  These are straws filled with lemon flavored ho...  \n",
       "568400  These are GREAT for carrying in my purse for e...  \n",
       "568402  I was disappointed in this product, as I had r...  \n",
       "568403  When I ordered these, based on the description...  \n",
       "568407  My 6 month old male Tuxedo cat likes Premium E...  \n",
       "568408  This is a good food with decent ingredients & ...  \n",
       "568409  I was very pleased with the ingredient quality...  \n",
       "568410  My main reason for the five star review has to...  \n",
       "568411  I bought this to try on two registered Maine C...  \n",
       "568412  When we brought home two 3-month-old purebred ...  \n",
       "568413  My cats don't like it. what else can I say to ...  \n",
       "\n",
       "[161949 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score[(df_score['UserId'].duplicated() == True) & (df_score['ProfileName'].duplicated() == True) &(df_score['Time'].duplicated() == True) & (df_score['Text'].duplicated() == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_score.sort_values('ProductId', axis = 0, ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data percentage reduced to after removing duplicates: 64.06375889693801\n"
     ]
    }
   ],
   "source": [
    "df_dup = df_sorted.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "print(\"Data percentage reduced to after removing duplicates:\" + ' ' + str(100*(len(df_dup['Id'])/len(df['Id']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64421</th>\n",
       "      <td>64422</td>\n",
       "      <td>B000MIDROQ</td>\n",
       "      <td>A161DK06JJMCYF</td>\n",
       "      <td>J. E. Stephens \"Jeanne\"</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1224892800</td>\n",
       "      <td>Bought This for My Son at College</td>\n",
       "      <td>My son loves spaghetti so I didn't hesitate or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44736</th>\n",
       "      <td>44737</td>\n",
       "      <td>B001EQ55RW</td>\n",
       "      <td>A2V0I904FH7ABY</td>\n",
       "      <td>Ram</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1212883200</td>\n",
       "      <td>Pure cocoa taste with crunchy almonds inside</td>\n",
       "      <td>It was almost a 'love at first bite' - the per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id   ProductId          UserId              ProfileName  \\\n",
       "64421  64422  B000MIDROQ  A161DK06JJMCYF  J. E. Stephens \"Jeanne\"   \n",
       "44736  44737  B001EQ55RW  A2V0I904FH7ABY                      Ram   \n",
       "\n",
       "       HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "64421                     3                       1      1  1224892800   \n",
       "44736                     3                       2      1  1212883200   \n",
       "\n",
       "                                            Summary  \\\n",
       "64421             Bought This for My Son at College   \n",
       "44736  Pure cocoa taste with crunchy almonds inside   \n",
       "\n",
       "                                                    Text  \n",
       "64421  My son loves spaghetti so I didn't hesitate or...  \n",
       "44736  It was almost a 'love at first bite' - the per...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup[df_dup['HelpfulnessNumerator'] > df_dup['HelpfulnessDenominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, ProductId, UserId, ProfileName, HelpfulnessNumerator, HelpfulnessDenominator, Score, Time, Summary, Text]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_dup[df_dup['HelpfulnessNumerator'] <= df_dup['HelpfulnessDenominator']]\n",
    "\n",
    "# Check if there is any data where HelpfulnessNumerator is greater than HelpfulnessDenominator\n",
    "df_final[df_final['HelpfulnessNumerator'] > df_final['HelpfulnessDenominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data percentage reduced to: 64.06340706547935\n"
     ]
    }
   ],
   "source": [
    "print(\"Data percentage reduced to:\" + ' ' + str(100*(len(df_final['Id'])/len(df['Id']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing:\n",
    "\n",
    "1) Remove HTML tag\n",
    "\n",
    "2) Remove punctuations and numbers\n",
    "\n",
    "3) Remove URLs\n",
    "\n",
    "4) Renaming short forms like can't to can not, 's to is, 're to are, etc\n",
    "\n",
    "5) Stop-word removal\n",
    "\n",
    "6) Stemming\n",
    "\n",
    "7) Change it to lowercase and join it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create an instance for SnowballStemmer\n",
    "ss = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know if it's the cactus or the tequila or just the unique combination of ingredients,. But I went through https://www.amazon.in/. but the flavour of this hot sauce makes it one of a kind! When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service!\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a sample text to see how text cleaning works.\n",
    "sam = \"I don't know if it's the cactus or the tequila or just the unique combination of ingredients,. But I went through https://www.amazon.in/. but the flavour of this hot sauce makes it one of a kind! When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service!\"\n",
    "sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation:\n",
    "    \n",
    "1) HTML tags: Text contains html tags like '< br />' '< br />', etc...\n",
    "\n",
    "2) URL: Text contains URL like https://www.amazon.in/\n",
    "\n",
    "3) Short words: Text contains short words like couldn't, it's, etc...\n",
    "\n",
    "4) Punctuation: Text contains punctuations like !.,''?\"\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML tag\n",
    "Defining function to remove HTML tag,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove HTML tags\n",
    "def html(ht):\n",
    "    ht = BeautifulSoup(ht, 'lxml').get_text()\n",
    "    return ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text before removing HTML tag: \n",
      "\n",
      "I don't know if it's the cactus or the tequila or just the unique combination of ingredients,. But I went through https://www.amazon.in/. but the flavour of this hot sauce makes it one of a kind! When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service! \n",
      "\n",
      "************************************************** \n",
      "\n",
      "Text after removing HTML tag:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know if it's the cactus or the tequila or just the unique combination of ingredients,. But I went through https://www.amazon.in/. but the flavour of this hot sauce makes it one of a kind! When we realized that we simply couldn't find it anywhere in our city we were bummed.Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.Thank you for the personal, incredible service!\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check html removal funcation on sample text sam\n",
    "\n",
    "print(\"Text before removing HTML tag:\",'\\n')\n",
    "print(sam, '\\n')\n",
    "print('*'*50, '\\n')\n",
    "\n",
    "print(\"Text after removing HTML tag:\")\n",
    "html(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL removal\n",
    "Defining a funtion to remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url(ur):\n",
    "    ur = re.sub(r\"http\\S+\", '', ur)\n",
    "    return ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text before removing URL: \n",
      "\n",
      "I don't know if it's the cactus or the tequila or just the unique combination of ingredients,. But I went through https://www.amazon.in/. but the flavour of this hot sauce makes it one of a kind! When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service! \n",
      "\n",
      "************************************************** \n",
      "\n",
      "Text after removing URL:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know if it's the cactus or the tequila or just the unique combination of ingredients,. But I went through  but the flavour of this hot sauce makes it one of a kind! When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service!\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check URL removal funcation on sample text sam\n",
    "\n",
    "print(\"Text before removing URL:\",'\\n')\n",
    "print(sam, '\\n')\n",
    "print('*'*50, '\\n')\n",
    "\n",
    "print(\"Text after removing URL:\")\n",
    "url(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short word to full word\n",
    "Defining a function to convert short words like couldn't to full word could not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_word(full_word):\n",
    "    \n",
    "    full_word = full_word.lower()              # Python reads Won't and won't as separate words. So change to lowercase\n",
    "    \n",
    "    full_word = re.sub(r\"won't\", \"will not\", full_word)\n",
    "    full_word = re.sub(r\"wouldn't\", \"would not\", full_word)\n",
    "    full_word = re.sub(r\"can't\", \"can not\", full_word)\n",
    "    full_word = re.sub(r\"don't\", \"don not\", full_word)\n",
    "    full_word = re.sub(r\"shouldn't\", \"should not\", full_word)\n",
    "    full_word = re.sub(r\"couldn't\", \"could not\", full_word)\n",
    "    full_word = re.sub(r\"\\'re\", \" are\", full_word)\n",
    "    full_word = re.sub(r\"\\'s\", \" is\", full_word)\n",
    "    full_word = re.sub(r\"\\'d\", \" would\", full_word)\n",
    "    full_word = re.sub(r\"\\'ll\", \" will\", full_word)\n",
    "    full_word = re.sub(r\"\\'ve\", \" have\", full_word)\n",
    "    full_word = re.sub(r\"\\'m\", \" am\", full_word)\n",
    "  \n",
    "    return full_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text before converting from short word to full word: \n",
      "\n",
      "I don't know if it's the cactus or the tequila or just the unique combination of ingredients,. But I went through https://www.amazon.in/. but the flavour of this hot sauce makes it one of a kind! When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service! \n",
      "\n",
      "************************************************** \n",
      "\n",
      "Text after converting from short word to full word:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i don not know if it is the cactus or the tequila or just the unique combination of ingredients,. but i went through https://www.amazon.in/. but the flavour of this hot sauce makes it one of a kind! when we realized that we simply could not find it anywhere in our city we were bummed.<br /><br />now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />if you love hot sauce..i mean really love hot sauce, but don not want a sauce that tastelessly burns your throat, grab a bottle of tequila picante gourmet de inclan.  just realize that once you taste it, you will never want to use any other sauce.<br /><br />thank you for the personal, incredible service!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check coversion of words from short form to full form\n",
    "\n",
    "print(\"Text before converting from short word to full word:\",'\\n')\n",
    "print(sam, '\\n')\n",
    "print('*'*50, '\\n')\n",
    "\n",
    "print(\"Text after converting from short word to full word:\")\n",
    "short_word(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punc(pun):\n",
    "    \n",
    "    pun = re.sub('[^a-zA-Z]', ' ', pun)\n",
    "    pun = pun.lower()\n",
    "    pun = pun.split()\n",
    "    \n",
    "    if len(pun) > 2:\n",
    "        pun = [ss.stem(sw) for sw in pun if sw not in stopwords.words('english')]\n",
    "        pun = ' '.join(pun)\n",
    "        return pun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new dataframe with 8k points\n",
    "df_ = df_final.sample(n = 200000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply text processing functions to 'Text' data\n",
    "HTML tag removal, url, punctuation, stop word removal, rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200000/200000 [1:25:39<00:00, 38.91it/s]\n"
     ]
    }
   ],
   "source": [
    "filtered = []                                    # All the filtered data is stored in this list\n",
    "positive = []                                    # All the positive review data is stored in this list\n",
    "negative = []                                    # All the negative review data is stored in this list\n",
    "\n",
    "for i, s in enumerate (tqdm(df_['Text'].values)):\n",
    "     \n",
    "    h = html(s)                                         # Removes HTML tag\n",
    "    u = url(h)                                          # Removes URL\n",
    "    f = short_word(u)                                   # Converts from short form to full form\n",
    "    p = punc(f)                                         # Removes punctuation, numbers, does stemming for the words > 2\n",
    "    \n",
    "    if df_['Score'].values[i] == 1:\n",
    "        positive.append(p)                               # Positive review list\n",
    "    if df_['Score'].values[i] == 0:\n",
    "        negative.append(p)                               # Negative review list\n",
    "        \n",
    "    filtered.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['Clean_text'] = filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean_Summary</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150523</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>use flour make sandwich bread gluten allerg so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451855</th>\n",
       "      <td>451856</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AIUWLEQ1ADEG5</td>\n",
       "      <td>Elizabeth Medina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>944092800</td>\n",
       "      <td>Entertainingl Funny!</td>\n",
       "      <td>Beetlejuice is a well written movie ..... ever...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>strawberri never tast good never eaten fresh s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374421</th>\n",
       "      <td>374422</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A1048CYU0OV4O8</td>\n",
       "      <td>Judy L. Eans</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>947376000</td>\n",
       "      <td>GREAT</td>\n",
       "      <td>THIS IS ONE MOVIE THAT SHOULD BE IN YOUR MOVIE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>packag label look differ one say mount sterl g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374399</th>\n",
       "      <td>374400</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A2DEE7F9XKP3ZR</td>\n",
       "      <td>jerome</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>959990400</td>\n",
       "      <td>Research - Beatlejuice video - French version</td>\n",
       "      <td>I'm getting crazy.I'm looking for Beatlejuice ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>use arrowhead mill flour year best baker glute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451902</th>\n",
       "      <td>451903</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>A2DEE7F9XKP3ZR</td>\n",
       "      <td>jerome</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>959990400</td>\n",
       "      <td>Research</td>\n",
       "      <td>I'm getting crazy.&lt;p&gt;Is it really impossible t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>like menthol cough drop gum might general avai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>1244</td>\n",
       "      <td>B00002Z754</td>\n",
       "      <td>A3B8RCEI0FXFI6</td>\n",
       "      <td>B G Chase</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>962236800</td>\n",
       "      <td>WOW Make your own 'slickers' !</td>\n",
       "      <td>I just received my shipment and could hardly w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dad move thailand year ago still ask send seas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId       ProfileName  \\\n",
       "150523  150524  0006641040   ACITT7DI6IDDL   shari zychinski   \n",
       "451855  451856  B00004CXX9   AIUWLEQ1ADEG5  Elizabeth Medina   \n",
       "374421  374422  B00004CI84  A1048CYU0OV4O8      Judy L. Eans   \n",
       "374399  374400  B00004CI84  A2DEE7F9XKP3ZR            jerome   \n",
       "451902  451903  B00004CXX9  A2DEE7F9XKP3ZR            jerome   \n",
       "1243      1244  B00002Z754  A3B8RCEI0FXFI6         B G Chase   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score       Time  \\\n",
       "150523                     0                       0      1  939340800   \n",
       "451855                     0                       0      1  944092800   \n",
       "374421                     2                       2      1  947376000   \n",
       "374399                     0                       3      1  959990400   \n",
       "451902                     0                       1      1  959990400   \n",
       "1243                      10                      10      1  962236800   \n",
       "\n",
       "                                              Summary  \\\n",
       "150523                      EVERY book is educational   \n",
       "451855                           Entertainingl Funny!   \n",
       "374421                                          GREAT   \n",
       "374399  Research - Beatlejuice video - French version   \n",
       "451902                                       Research   \n",
       "1243                   WOW Make your own 'slickers' !   \n",
       "\n",
       "                                                     Text  Clean_Summary  \\\n",
       "150523  this witty little book makes my son laugh at l...            NaN   \n",
       "451855  Beetlejuice is a well written movie ..... ever...            NaN   \n",
       "374421  THIS IS ONE MOVIE THAT SHOULD BE IN YOUR MOVIE...            NaN   \n",
       "374399  I'm getting crazy.I'm looking for Beatlejuice ...            NaN   \n",
       "451902  I'm getting crazy.<p>Is it really impossible t...            NaN   \n",
       "1243    I just received my shipment and could hardly w...            NaN   \n",
       "\n",
       "                                               Clean_text  \n",
       "150523  use flour make sandwich bread gluten allerg so...  \n",
       "451855  strawberri never tast good never eaten fresh s...  \n",
       "374421  packag label look differ one say mount sterl g...  \n",
       "374399  use arrowhead mill flour year best baker glute...  \n",
       "451902  like menthol cough drop gum might general avai...  \n",
       "1243    dad move thailand year ago still ask send seas...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_.sort_values('Time', ascending = True)\n",
    "df_.to_csv('D:/ALL learnings/ML/Applied ai/Assinments/lstm on amazonfine reviews/Amazon_8k_time.csv', index_label = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_['Clean_Summary']\n",
    "# print(\"Shape of X is:\" + ' ' + str(X.shape))\n",
    "\n",
    "# y = df_['Score']\n",
    "# print(\"Shape of y is:\" + ' ' + str(y.shape),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    168526\n",
       "0     31474\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_['Clean_Summary'] = df_['Clean_Summary'].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict()\n",
    "for sent in df_['Clean_text'].values:\n",
    "    for word in sent.split():\n",
    "        if word not in vocab.keys():\n",
    "            vocab[word] = 1\n",
    "        else:\n",
    "            vocab[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63720"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_dict = sorted(vocab.items(), key=operator.itemgetter(1),reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63720"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = dict()\n",
    "rank = 1\n",
    "for i in range(len(sorted_dict)):\n",
    "    k = sorted_dict[i][0]\n",
    "    ranking[k] = rank\n",
    "    rank+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 12)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200000/200000 [00:05<00:00, 36056.73it/s]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "X = []\n",
    "for sent in tqdm(df_['Clean_text'].values):\n",
    "    r_ = []\n",
    "    for word in sent.split():\n",
    "        r_.append(ranking[word])\n",
    "    X.append(r_)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great deal indian food ever quick cheap easi prepar may littl small two serv definit enough basmati rice cumin two ad small dish chutney side roti well made nice vegetarian meal two packag suggest meat eater add cook meat sauc actual think add leftov fri paneer chees next time make rather spici econom'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_['Clean_text'][4341]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_['Clean_text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_['Clean_text']=df_['Clean_text'].fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "change = lambda x : 1 if x == 1 else 0\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:100000]\n",
    "y = y[:100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Apply LSTM models:</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size = 0.3,random_state = 0,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_dynamic(x, vy, ty):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    plt.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.xlabel('Epochs') \n",
    "    plt.ylabel('Binary Crossentropy Loss')\n",
    "    plt.title('\\nBinary Crossentropy Loss VS Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model 1- LSTM layer with Adadelta optimizer</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=0\n",
    "for i in range(len(X_train)):\n",
    "    if len(X_train[i]) > m:\n",
    "        m=len(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length->  1034\n"
     ]
    }
   ],
   "source": [
    "print('max length-> ',m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 1024)\n",
      "[  0   0   0 ... 868 656   3]\n"
     ]
    }
   ],
   "source": [
    "# truncate and/or pad input sequences\n",
    "max_review_length = 1024\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 01:03:26.032189 15092 deprecation_wrapper.py:119] From C:\\Users\\HARRY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0819 01:03:26.103476 15092 deprecation_wrapper.py:119] From C:\\Users\\HARRY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0819 01:03:26.134338 15092 deprecation_wrapper.py:119] From C:\\Users\\HARRY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0819 01:03:26.689989 15092 deprecation_wrapper.py:119] From C:\\Users\\HARRY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0819 01:03:26.716525 15092 deprecation_wrapper.py:119] From C:\\Users\\HARRY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0819 01:03:26.727472 15092 deprecation.py:323] From C:\\Users\\HARRY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1024, 50)          3186050   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 70)                33880     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 3,220,001\n",
      "Trainable params: 3,220,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab.keys())+1, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(70))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 01:04:38.849311 15092 deprecation_wrapper.py:119] From C:\\Users\\HARRY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70000 samples, validate on 30000 samples\n",
      "Epoch 1/8\n",
      "70000/70000 [==============================] - ETA: 39:26 - loss: 0.6933 - acc: 0.47 - ETA: 41:51 - loss: 0.6907 - acc: 0.65 - ETA: 44:18 - loss: 0.6879 - acc: 0.72 - ETA: 46:31 - loss: 0.6853 - acc: 0.75 - ETA: 48:23 - loss: 0.6825 - acc: 0.77 - ETA: 48:46 - loss: 0.6794 - acc: 0.79 - ETA: 48:53 - loss: 0.6766 - acc: 0.80 - ETA: 50:00 - loss: 0.6730 - acc: 0.81 - ETA: 51:33 - loss: 0.6698 - acc: 0.81 - ETA: 53:22 - loss: 0.6660 - acc: 0.82 - ETA: 54:32 - loss: 0.6616 - acc: 0.82 - ETA: 54:43 - loss: 0.6562 - acc: 0.83 - ETA: 54:55 - loss: 0.6506 - acc: 0.83 - ETA: 55:07 - loss: 0.6419 - acc: 0.83 - ETA: 55:37 - loss: 0.6317 - acc: 0.83 - ETA: 55:47 - loss: 0.6182 - acc: 0.83 - ETA: 55:58 - loss: 0.6048 - acc: 0.84 - ETA: 56:20 - loss: 0.5937 - acc: 0.84 - ETA: 55:54 - loss: 0.5825 - acc: 0.84 - ETA: 55:45 - loss: 0.5731 - acc: 0.84 - ETA: 55:35 - loss: 0.5640 - acc: 0.84 - ETA: 55:15 - loss: 0.5548 - acc: 0.84 - ETA: 55:03 - loss: 0.5480 - acc: 0.84 - ETA: 54:51 - loss: 0.5418 - acc: 0.84 - ETA: 54:35 - loss: 0.5352 - acc: 0.85 - ETA: 54:38 - loss: 0.5281 - acc: 0.85 - ETA: 54:31 - loss: 0.5242 - acc: 0.85 - ETA: 54:04 - loss: 0.5190 - acc: 0.85 - ETA: 53:39 - loss: 0.5139 - acc: 0.85 - ETA: 53:09 - loss: 0.5102 - acc: 0.85 - ETA: 52:31 - loss: 0.5056 - acc: 0.85 - ETA: 51:55 - loss: 0.5020 - acc: 0.85 - ETA: 51:09 - loss: 0.4988 - acc: 0.85 - ETA: 49:48 - loss: 0.4962 - acc: 0.85 - ETA: 47:47 - loss: 0.4934 - acc: 0.85 - ETA: 45:47 - loss: 0.4906 - acc: 0.85 - ETA: 43:52 - loss: 0.4872 - acc: 0.85 - ETA: 42:01 - loss: 0.4847 - acc: 0.85 - ETA: 40:14 - loss: 0.4828 - acc: 0.85 - ETA: 38:32 - loss: 0.4801 - acc: 0.85 - ETA: 36:52 - loss: 0.4786 - acc: 0.85 - ETA: 35:15 - loss: 0.4762 - acc: 0.85 - ETA: 33:41 - loss: 0.4754 - acc: 0.85 - ETA: 32:09 - loss: 0.4735 - acc: 0.85 - ETA: 30:40 - loss: 0.4727 - acc: 0.85 - ETA: 29:13 - loss: 0.4703 - acc: 0.85 - ETA: 27:47 - loss: 0.4692 - acc: 0.85 - ETA: 26:23 - loss: 0.4671 - acc: 0.85 - ETA: 25:01 - loss: 0.4652 - acc: 0.85 - ETA: 23:40 - loss: 0.4632 - acc: 0.86 - ETA: 22:22 - loss: 0.4616 - acc: 0.86 - ETA: 21:05 - loss: 0.4605 - acc: 0.86 - ETA: 19:49 - loss: 0.4588 - acc: 0.86 - ETA: 18:33 - loss: 0.4570 - acc: 0.86 - ETA: 17:19 - loss: 0.4556 - acc: 0.86 - ETA: 16:06 - loss: 0.4542 - acc: 0.86 - ETA: 14:53 - loss: 0.4533 - acc: 0.86 - ETA: 13:42 - loss: 0.4520 - acc: 0.86 - ETA: 12:31 - loss: 0.4506 - acc: 0.86 - ETA: 11:21 - loss: 0.4502 - acc: 0.86 - ETA: 10:11 - loss: 0.4492 - acc: 0.86 - ETA: 9:02 - loss: 0.4484 - acc: 0.8620 - ETA: 7:53 - loss: 0.4473 - acc: 0.862 - ETA: 6:44 - loss: 0.4469 - acc: 0.862 - ETA: 5:36 - loss: 0.4453 - acc: 0.862 - ETA: 4:28 - loss: 0.4448 - acc: 0.862 - ETA: 3:21 - loss: 0.4437 - acc: 0.862 - ETA: 2:13 - loss: 0.4430 - acc: 0.862 - ETA: 1:06 - loss: 0.4424 - acc: 0.862 - 4820s 69ms/step - loss: 0.4415 - acc: 0.8630 - val_loss: 0.4559 - val_acc: 0.8347\n",
      "Epoch 2/8\n",
      "70000/70000 [==============================] - ETA: 1:09:55 - loss: 0.3710 - acc: 0.87 - ETA: 1:09:16 - loss: 0.3845 - acc: 0.87 - ETA: 1:08:23 - loss: 0.3932 - acc: 0.86 - ETA: 1:07:49 - loss: 0.3850 - acc: 0.87 - ETA: 1:07:05 - loss: 0.3731 - acc: 0.87 - ETA: 1:06:18 - loss: 0.3828 - acc: 0.87 - ETA: 1:05:25 - loss: 0.3816 - acc: 0.87 - ETA: 1:04:41 - loss: 0.3846 - acc: 0.87 - ETA: 1:03:52 - loss: 0.3845 - acc: 0.87 - ETA: 1:03:08 - loss: 0.3849 - acc: 0.87 - ETA: 1:02:13 - loss: 0.3861 - acc: 0.87 - ETA: 1:01:27 - loss: 0.3895 - acc: 0.86 - ETA: 1:00:32 - loss: 0.3922 - acc: 0.86 - ETA: 59:42 - loss: 0.3933 - acc: 0.8669 - ETA: 58:48 - loss: 0.3935 - acc: 0.86 - ETA: 57:51 - loss: 0.3940 - acc: 0.86 - ETA: 56:51 - loss: 0.3930 - acc: 0.86 - ETA: 55:55 - loss: 0.3911 - acc: 0.86 - ETA: 54:59 - loss: 0.3904 - acc: 0.86 - ETA: 54:03 - loss: 0.3893 - acc: 0.86 - ETA: 53:07 - loss: 0.3911 - acc: 0.86 - ETA: 52:09 - loss: 0.3905 - acc: 0.86 - ETA: 51:17 - loss: 0.3908 - acc: 0.86 - ETA: 50:21 - loss: 0.3903 - acc: 0.86 - ETA: 49:24 - loss: 0.3908 - acc: 0.86 - ETA: 48:28 - loss: 0.3916 - acc: 0.86 - ETA: 47:35 - loss: 0.3913 - acc: 0.86 - ETA: 46:38 - loss: 0.3911 - acc: 0.86 - ETA: 45:40 - loss: 0.3905 - acc: 0.86 - ETA: 44:43 - loss: 0.3907 - acc: 0.86 - ETA: 43:45 - loss: 0.3922 - acc: 0.86 - ETA: 42:46 - loss: 0.3914 - acc: 0.86 - ETA: 41:47 - loss: 0.3917 - acc: 0.86 - ETA: 40:45 - loss: 0.3916 - acc: 0.86 - ETA: 39:45 - loss: 0.3917 - acc: 0.86 - ETA: 38:44 - loss: 0.3915 - acc: 0.86 - ETA: 37:42 - loss: 0.3918 - acc: 0.86 - ETA: 36:39 - loss: 0.3915 - acc: 0.86 - ETA: 35:36 - loss: 0.3917 - acc: 0.86 - ETA: 34:32 - loss: 0.3917 - acc: 0.86 - ETA: 33:29 - loss: 0.3919 - acc: 0.86 - ETA: 32:24 - loss: 0.3919 - acc: 0.86 - ETA: 31:19 - loss: 0.3918 - acc: 0.86 - ETA: 30:15 - loss: 0.3913 - acc: 0.86 - ETA: 29:09 - loss: 0.3909 - acc: 0.86 - ETA: 28:03 - loss: 0.3909 - acc: 0.86 - ETA: 26:57 - loss: 0.3901 - acc: 0.86 - ETA: 25:51 - loss: 0.3901 - acc: 0.86 - ETA: 24:43 - loss: 0.3898 - acc: 0.86 - ETA: 23:36 - loss: 0.3902 - acc: 0.86 - ETA: 22:29 - loss: 0.3904 - acc: 0.86 - ETA: 21:20 - loss: 0.3898 - acc: 0.86 - ETA: 20:12 - loss: 0.3893 - acc: 0.86 - ETA: 19:03 - loss: 0.3888 - acc: 0.86 - ETA: 17:53 - loss: 0.3889 - acc: 0.86 - ETA: 16:43 - loss: 0.3892 - acc: 0.86 - ETA: 15:34 - loss: 0.3890 - acc: 0.86 - ETA: 14:24 - loss: 0.3896 - acc: 0.86 - ETA: 13:13 - loss: 0.3889 - acc: 0.86 - ETA: 12:02 - loss: 0.3889 - acc: 0.86 - ETA: 10:51 - loss: 0.3884 - acc: 0.86 - ETA: 9:40 - loss: 0.3882 - acc: 0.8695 - ETA: 8:28 - loss: 0.3881 - acc: 0.869 - ETA: 7:17 - loss: 0.3881 - acc: 0.869 - ETA: 6:05 - loss: 0.3876 - acc: 0.869 - ETA: 4:52 - loss: 0.3875 - acc: 0.869 - ETA: 3:39 - loss: 0.3882 - acc: 0.869 - ETA: 2:26 - loss: 0.3883 - acc: 0.869 - ETA: 1:13 - loss: 0.3886 - acc: 0.869 - 5337s 76ms/step - loss: 0.3885 - acc: 0.8694 - val_loss: 0.4562 - val_acc: 0.8347\n",
      "Epoch 3/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 1:36:32 - loss: 0.3433 - acc: 0.89 - ETA: 1:34:13 - loss: 0.3692 - acc: 0.87 - ETA: 1:32:46 - loss: 0.3805 - acc: 0.87 - ETA: 1:31:42 - loss: 0.3879 - acc: 0.86 - ETA: 1:30:41 - loss: 0.3938 - acc: 0.86 - ETA: 1:29:18 - loss: 0.3912 - acc: 0.86 - ETA: 1:27:57 - loss: 0.3900 - acc: 0.86 - ETA: 1:26:42 - loss: 0.3937 - acc: 0.86 - ETA: 1:25:16 - loss: 0.3936 - acc: 0.86 - ETA: 1:23:58 - loss: 0.3931 - acc: 0.86 - ETA: 1:22:42 - loss: 0.3913 - acc: 0.86 - ETA: 1:21:18 - loss: 0.3916 - acc: 0.86 - ETA: 1:20:00 - loss: 0.3905 - acc: 0.86 - ETA: 1:18:42 - loss: 0.3902 - acc: 0.86 - ETA: 1:17:26 - loss: 0.3897 - acc: 0.86 - ETA: 1:16:09 - loss: 0.3887 - acc: 0.86 - ETA: 1:14:51 - loss: 0.3875 - acc: 0.86 - ETA: 1:13:27 - loss: 0.3888 - acc: 0.86 - ETA: 1:12:12 - loss: 0.3881 - acc: 0.86 - ETA: 1:10:48 - loss: 0.3904 - acc: 0.86 - ETA: 1:09:23 - loss: 0.3902 - acc: 0.86 - ETA: 1:07:59 - loss: 0.3909 - acc: 0.86 - ETA: 1:06:36 - loss: 0.3916 - acc: 0.86 - ETA: 1:05:13 - loss: 0.3923 - acc: 0.86 - ETA: 1:03:49 - loss: 0.3916 - acc: 0.86 - ETA: 1:02:25 - loss: 0.3905 - acc: 0.86 - ETA: 1:01:04 - loss: 0.3895 - acc: 0.86 - ETA: 59:43 - loss: 0.3900 - acc: 0.8684 - ETA: 58:24 - loss: 0.3900 - acc: 0.86 - ETA: 57:02 - loss: 0.3899 - acc: 0.86 - ETA: 55:37 - loss: 0.3896 - acc: 0.86 - ETA: 54:14 - loss: 0.3887 - acc: 0.86 - ETA: 52:49 - loss: 0.3880 - acc: 0.86 - ETA: 51:25 - loss: 0.3870 - acc: 0.86 - ETA: 49:59 - loss: 0.3866 - acc: 0.87 - ETA: 48:36 - loss: 0.3863 - acc: 0.87 - ETA: 47:13 - loss: 0.3870 - acc: 0.86 - ETA: 45:49 - loss: 0.3873 - acc: 0.86 - ETA: 44:25 - loss: 0.3869 - acc: 0.86 - ETA: 42:59 - loss: 0.3874 - acc: 0.86 - ETA: 41:34 - loss: 0.3882 - acc: 0.86 - ETA: 40:08 - loss: 0.3883 - acc: 0.86 - ETA: 38:44 - loss: 0.3877 - acc: 0.86 - ETA: 37:18 - loss: 0.3876 - acc: 0.86 - ETA: 35:52 - loss: 0.3873 - acc: 0.86 - ETA: 34:27 - loss: 0.3872 - acc: 0.86 - ETA: 33:02 - loss: 0.3872 - acc: 0.86 - ETA: 31:37 - loss: 0.3874 - acc: 0.86 - ETA: 30:11 - loss: 0.3873 - acc: 0.86 - ETA: 28:46 - loss: 0.3869 - acc: 0.86 - ETA: 27:20 - loss: 0.3864 - acc: 0.87 - ETA: 25:54 - loss: 0.3860 - acc: 0.87 - ETA: 24:29 - loss: 0.3864 - acc: 0.87 - ETA: 23:03 - loss: 0.3870 - acc: 0.86 - ETA: 21:37 - loss: 0.3868 - acc: 0.86 - ETA: 20:11 - loss: 0.3874 - acc: 0.86 - ETA: 18:45 - loss: 0.3870 - acc: 0.86 - ETA: 17:19 - loss: 0.3873 - acc: 0.86 - ETA: 15:53 - loss: 0.3871 - acc: 0.86 - ETA: 14:27 - loss: 0.3875 - acc: 0.86 - ETA: 13:00 - loss: 0.3876 - acc: 0.86 - ETA: 11:34 - loss: 0.3873 - acc: 0.86 - ETA: 10:07 - loss: 0.3873 - acc: 0.86 - ETA: 8:41 - loss: 0.3873 - acc: 0.8697 - ETA: 7:14 - loss: 0.3876 - acc: 0.869 - ETA: 5:47 - loss: 0.3875 - acc: 0.869 - ETA: 4:21 - loss: 0.3877 - acc: 0.869 - ETA: 2:54 - loss: 0.3878 - acc: 0.869 - ETA: 1:27 - loss: 0.3879 - acc: 0.869 - 6288s 90ms/step - loss: 0.3880 - acc: 0.8694 - val_loss: 0.4530 - val_acc: 0.8347\n",
      "Epoch 4/8\n",
      "70000/70000 [==============================] - ETA: 1:42:21 - loss: 0.3751 - acc: 0.87 - ETA: 1:41:15 - loss: 0.3946 - acc: 0.86 - ETA: 1:39:18 - loss: 0.3870 - acc: 0.87 - ETA: 1:37:33 - loss: 0.3855 - acc: 0.87 - ETA: 1:36:15 - loss: 0.3876 - acc: 0.86 - ETA: 1:34:35 - loss: 0.3915 - acc: 0.86 - ETA: 1:33:18 - loss: 0.3891 - acc: 0.86 - ETA: 1:31:57 - loss: 0.3908 - acc: 0.86 - ETA: 1:30:36 - loss: 0.3900 - acc: 0.86 - ETA: 1:29:09 - loss: 0.3892 - acc: 0.86 - ETA: 1:27:44 - loss: 0.3917 - acc: 0.86 - ETA: 1:26:01 - loss: 0.3894 - acc: 0.86 - ETA: 1:24:32 - loss: 0.3902 - acc: 0.86 - ETA: 1:23:09 - loss: 0.3914 - acc: 0.86 - ETA: 1:21:49 - loss: 0.3941 - acc: 0.86 - ETA: 1:20:25 - loss: 0.3924 - acc: 0.86 - ETA: 1:18:55 - loss: 0.3913 - acc: 0.86 - ETA: 1:17:23 - loss: 0.3933 - acc: 0.86 - ETA: 1:15:57 - loss: 0.3927 - acc: 0.86 - ETA: 1:14:28 - loss: 0.3915 - acc: 0.86 - ETA: 1:13:01 - loss: 0.3913 - acc: 0.86 - ETA: 1:11:33 - loss: 0.3893 - acc: 0.86 - ETA: 1:10:05 - loss: 0.3893 - acc: 0.86 - ETA: 1:08:34 - loss: 0.3890 - acc: 0.86 - ETA: 1:07:06 - loss: 0.3890 - acc: 0.86 - ETA: 1:05:39 - loss: 0.3883 - acc: 0.86 - ETA: 1:04:13 - loss: 0.3881 - acc: 0.86 - ETA: 1:02:43 - loss: 0.3891 - acc: 0.86 - ETA: 1:01:17 - loss: 0.3886 - acc: 0.86 - ETA: 59:45 - loss: 0.3891 - acc: 0.8690 - ETA: 58:16 - loss: 0.3888 - acc: 0.86 - ETA: 56:46 - loss: 0.3895 - acc: 0.86 - ETA: 55:15 - loss: 0.3902 - acc: 0.86 - ETA: 53:46 - loss: 0.3901 - acc: 0.86 - ETA: 52:20 - loss: 0.3902 - acc: 0.86 - ETA: 50:53 - loss: 0.3903 - acc: 0.86 - ETA: 50:16 - loss: 0.3902 - acc: 0.86 - ETA: 49:48 - loss: 0.3895 - acc: 0.86 - ETA: 49:12 - loss: 0.3897 - acc: 0.86 - ETA: 48:32 - loss: 0.3895 - acc: 0.86 - ETA: 47:44 - loss: 0.3892 - acc: 0.86 - ETA: 46:52 - loss: 0.3892 - acc: 0.86 - ETA: 45:53 - loss: 0.3886 - acc: 0.86 - ETA: 44:48 - loss: 0.3889 - acc: 0.86 - ETA: 43:42 - loss: 0.3888 - acc: 0.86 - ETA: 42:29 - loss: 0.3886 - acc: 0.86 - ETA: 41:12 - loss: 0.3895 - acc: 0.86 - ETA: 39:53 - loss: 0.3897 - acc: 0.86 - ETA: 38:28 - loss: 0.3893 - acc: 0.86 - ETA: 37:02 - loss: 0.3891 - acc: 0.86 - ETA: 41:29 - loss: 0.3897 - acc: 0.86 - ETA: 39:28 - loss: 0.3896 - acc: 0.86 - ETA: 37:30 - loss: 0.3893 - acc: 0.86 - ETA: 35:30 - loss: 0.3894 - acc: 0.86 - ETA: 33:30 - loss: 0.3890 - acc: 0.86 - ETA: 31:29 - loss: 0.3887 - acc: 0.86 - ETA: 29:27 - loss: 0.3887 - acc: 0.86 - ETA: 27:21 - loss: 0.3891 - acc: 0.86 - ETA: 25:13 - loss: 0.3891 - acc: 0.86 - ETA: 23:03 - loss: 0.3893 - acc: 0.86 - ETA: 24:36 - loss: 0.3893 - acc: 0.86 - ETA: 21:48 - loss: 0.3897 - acc: 0.86 - ETA: 19:06 - loss: 0.3897 - acc: 0.86 - ETA: 16:24 - loss: 0.3895 - acc: 0.86 - ETA: 13:38 - loss: 0.3894 - acc: 0.86 - ETA: 10:50 - loss: 0.3892 - acc: 0.86 - ETA: 8:04 - loss: 0.3893 - acc: 0.8688 - ETA: 5:21 - loss: 0.3888 - acc: 0.869 - ETA: 2:39 - loss: 0.3884 - acc: 0.869 - 11307s 162ms/step - loss: 0.3881 - acc: 0.8694 - val_loss: 0.4566 - val_acc: 0.8347\n",
      "Epoch 5/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 2:10:46 - loss: 0.3826 - acc: 0.87 - ETA: 2:07:06 - loss: 0.3826 - acc: 0.87 - ETA: 1:58:05 - loss: 0.3838 - acc: 0.87 - ETA: 1:52:50 - loss: 0.3896 - acc: 0.86 - ETA: 1:50:08 - loss: 0.3902 - acc: 0.86 - ETA: 1:46:25 - loss: 0.3873 - acc: 0.86 - ETA: 1:43:34 - loss: 0.3849 - acc: 0.87 - ETA: 1:41:19 - loss: 0.3816 - acc: 0.87 - ETA: 1:39:18 - loss: 0.3879 - acc: 0.86 - ETA: 1:37:26 - loss: 0.3870 - acc: 0.87 - ETA: 1:35:22 - loss: 0.3898 - acc: 0.86 - ETA: 1:33:37 - loss: 0.3919 - acc: 0.86 - ETA: 1:31:51 - loss: 0.3934 - acc: 0.86 - ETA: 1:30:13 - loss: 0.3922 - acc: 0.86 - ETA: 1:28:27 - loss: 0.3924 - acc: 0.86 - ETA: 1:26:55 - loss: 0.3896 - acc: 0.86 - ETA: 1:25:10 - loss: 0.3900 - acc: 0.86 - ETA: 1:23:22 - loss: 0.3906 - acc: 0.86 - ETA: 1:22:34 - loss: 0.3897 - acc: 0.86 - ETA: 1:20:49 - loss: 0.3890 - acc: 0.86 - ETA: 1:19:15 - loss: 0.3881 - acc: 0.86 - ETA: 1:17:26 - loss: 0.3875 - acc: 0.86 - ETA: 1:15:43 - loss: 0.3883 - acc: 0.86 - ETA: 1:13:58 - loss: 0.3881 - acc: 0.86 - ETA: 1:12:14 - loss: 0.3869 - acc: 0.87 - ETA: 1:10:30 - loss: 0.3861 - acc: 0.87 - ETA: 1:08:47 - loss: 0.3861 - acc: 0.87 - ETA: 1:07:10 - loss: 0.3851 - acc: 0.87 - ETA: 1:05:44 - loss: 0.3863 - acc: 0.87 - ETA: 1:04:14 - loss: 0.3865 - acc: 0.87 - ETA: 1:02:39 - loss: 0.3867 - acc: 0.87 - ETA: 1:01:04 - loss: 0.3871 - acc: 0.86 - ETA: 59:30 - loss: 0.3871 - acc: 0.8698 - ETA: 57:53 - loss: 0.3879 - acc: 0.86 - ETA: 56:19 - loss: 0.3877 - acc: 0.86 - ETA: 54:41 - loss: 0.3868 - acc: 0.87 - ETA: 53:05 - loss: 0.3872 - acc: 0.86 - ETA: 51:34 - loss: 0.3871 - acc: 0.86 - ETA: 49:59 - loss: 0.3869 - acc: 0.87 - ETA: 48:23 - loss: 0.3871 - acc: 0.86 - ETA: 46:58 - loss: 0.3864 - acc: 0.87 - ETA: 45:49 - loss: 0.3864 - acc: 0.87 - ETA: 44:35 - loss: 0.3857 - acc: 0.87 - ETA: 43:02 - loss: 0.3869 - acc: 0.87 - ETA: 41:29 - loss: 0.3879 - acc: 0.86 - ETA: 39:54 - loss: 0.3875 - acc: 0.86 - ETA: 38:14 - loss: 0.3874 - acc: 0.86 - ETA: 36:39 - loss: 0.3876 - acc: 0.86 - ETA: 35:06 - loss: 0.3871 - acc: 0.86 - ETA: 33:27 - loss: 0.3872 - acc: 0.86 - ETA: 31:50 - loss: 0.3880 - acc: 0.86 - ETA: 30:30 - loss: 0.3878 - acc: 0.86 - ETA: 29:12 - loss: 0.3878 - acc: 0.86 - ETA: 27:49 - loss: 0.3873 - acc: 0.86 - ETA: 26:23 - loss: 0.3880 - acc: 0.86 - ETA: 24:54 - loss: 0.3876 - acc: 0.86 - ETA: 23:22 - loss: 0.3882 - acc: 0.86 - ETA: 21:48 - loss: 0.3879 - acc: 0.86 - ETA: 20:12 - loss: 0.3879 - acc: 0.86 - ETA: 18:34 - loss: 0.3884 - acc: 0.86 - ETA: 16:51 - loss: 0.3884 - acc: 0.86 - ETA: 15:06 - loss: 0.3881 - acc: 0.86 - ETA: 13:19 - loss: 0.3878 - acc: 0.86 - ETA: 11:31 - loss: 0.3881 - acc: 0.86 - ETA: 9:40 - loss: 0.3882 - acc: 0.8694 - ETA: 7:47 - loss: 0.3882 - acc: 0.869 - ETA: 5:52 - loss: 0.3882 - acc: 0.869 - ETA: 3:56 - loss: 0.3879 - acc: 0.869 - ETA: 1:59 - loss: 0.3882 - acc: 0.869 - 8769s 125ms/step - loss: 0.3882 - acc: 0.8694 - val_loss: 0.4527 - val_acc: 0.8347\n",
      "Epoch 6/8\n",
      "70000/70000 [==============================] - ETA: 3:16:52 - loss: 0.3901 - acc: 0.86 - ETA: 3:15:11 - loss: 0.4042 - acc: 0.86 - ETA: 3:12:08 - loss: 0.4081 - acc: 0.85 - ETA: 3:10:04 - loss: 0.3897 - acc: 0.86 - ETA: 3:07:52 - loss: 0.3937 - acc: 0.86 - ETA: 3:07:26 - loss: 0.3903 - acc: 0.86 - ETA: 7:11:53 - loss: 0.3934 - acc: 0.86 - ETA: 6:27:05 - loss: 0.3901 - acc: 0.86 - ETA: 5:59:28 - loss: 0.3923 - acc: 0.86 - ETA: 5:36:33 - loss: 0.3929 - acc: 0.86 - ETA: 5:17:47 - loss: 0.3911 - acc: 0.86 - ETA: 5:00:26 - loss: 0.3896 - acc: 0.86 - ETA: 4:45:08 - loss: 0.3878 - acc: 0.86 - ETA: 4:32:22 - loss: 0.3845 - acc: 0.87 - ETA: 4:20:25 - loss: 0.3859 - acc: 0.87 - ETA: 4:10:30 - loss: 0.3859 - acc: 0.87 - ETA: 4:00:41 - loss: 0.3862 - acc: 0.87 - ETA: 3:51:19 - loss: 0.3866 - acc: 0.87 - ETA: 3:42:38 - loss: 0.3846 - acc: 0.87 - ETA: 3:34:26 - loss: 0.3852 - acc: 0.87 - ETA: 3:26:44 - loss: 0.3839 - acc: 0.87 - ETA: 3:19:40 - loss: 0.3846 - acc: 0.87 - ETA: 3:13:08 - loss: 0.3840 - acc: 0.87 - ETA: 3:06:51 - loss: 0.3847 - acc: 0.87 - ETA: 3:01:09 - loss: 0.3847 - acc: 0.87 - ETA: 2:55:14 - loss: 0.3830 - acc: 0.87 - ETA: 2:49:37 - loss: 0.3823 - acc: 0.87 - ETA: 2:43:56 - loss: 0.3830 - acc: 0.87 - ETA: 2:38:44 - loss: 0.3826 - acc: 0.87 - ETA: 2:33:28 - loss: 0.3832 - acc: 0.87 - ETA: 2:28:17 - loss: 0.3839 - acc: 0.87 - ETA: 2:23:16 - loss: 0.3843 - acc: 0.87 - ETA: 2:18:32 - loss: 0.3844 - acc: 0.87 - ETA: 2:14:00 - loss: 0.3851 - acc: 0.87 - ETA: 2:09:25 - loss: 0.3854 - acc: 0.87 - ETA: 2:04:53 - loss: 0.3854 - acc: 0.87 - ETA: 2:00:28 - loss: 0.3853 - acc: 0.87 - ETA: 1:56:12 - loss: 0.3858 - acc: 0.87 - ETA: 1:52:04 - loss: 0.3855 - acc: 0.87 - ETA: 1:47:53 - loss: 0.3855 - acc: 0.87 - ETA: 1:44:37 - loss: 0.3861 - acc: 0.87 - ETA: 1:41:22 - loss: 0.3851 - acc: 0.87 - ETA: 1:38:04 - loss: 0.3855 - acc: 0.87 - ETA: 1:34:44 - loss: 0.3851 - acc: 0.87 - ETA: 1:46:24 - loss: 0.3858 - acc: 0.87 - ETA: 1:40:46 - loss: 0.3856 - acc: 0.87 - ETA: 1:35:15 - loss: 0.3858 - acc: 0.87 - ETA: 1:30:03 - loss: 0.3858 - acc: 0.87 - ETA: 1:24:59 - loss: 0.3867 - acc: 0.87 - ETA: 1:19:56 - loss: 0.3865 - acc: 0.87 - ETA: 1:15:02 - loss: 0.3859 - acc: 0.87 - ETA: 1:10:16 - loss: 0.3856 - acc: 0.87 - ETA: 1:05:44 - loss: 0.3857 - acc: 0.87 - ETA: 1:01:23 - loss: 0.3853 - acc: 0.87 - ETA: 57:03 - loss: 0.3855 - acc: 0.8708 - ETA: 52:43 - loss: 0.3860 - acc: 0.87 - ETA: 48:31 - loss: 0.3861 - acc: 0.87 - ETA: 44:24 - loss: 0.3866 - acc: 0.87 - ETA: 40:19 - loss: 0.3864 - acc: 0.87 - ETA: 36:19 - loss: 0.3865 - acc: 0.87 - ETA: 32:23 - loss: 0.3867 - acc: 0.87 - ETA: 28:32 - loss: 0.3867 - acc: 0.87 - ETA: 24:45 - loss: 0.3868 - acc: 0.87 - ETA: 21:03 - loss: 0.3871 - acc: 0.86 - ETA: 17:25 - loss: 0.3874 - acc: 0.86 - ETA: 13:49 - loss: 0.3873 - acc: 0.86 - ETA: 10:18 - loss: 0.3874 - acc: 0.86 - ETA: 6:49 - loss: 0.3878 - acc: 0.8695 - ETA: 3:23 - loss: 0.3879 - acc: 0.869 - 14306s 204ms/step - loss: 0.3880 - acc: 0.8694 - val_loss: 0.4526 - val_acc: 0.8347\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 1:53:57 - loss: 0.3878 - acc: 0.86 - ETA: 1:52:10 - loss: 0.3880 - acc: 0.86 - ETA: 1:52:45 - loss: 0.3786 - acc: 0.87 - ETA: 1:52:46 - loss: 0.3792 - acc: 0.87 - ETA: 1:50:11 - loss: 0.3842 - acc: 0.87 - ETA: 1:49:20 - loss: 0.3763 - acc: 0.87 - ETA: 1:46:35 - loss: 0.3769 - acc: 0.87 - ETA: 1:44:16 - loss: 0.3798 - acc: 0.87 - ETA: 1:42:33 - loss: 0.3824 - acc: 0.87 - ETA: 1:41:06 - loss: 0.3820 - acc: 0.87 - ETA: 1:38:57 - loss: 0.3844 - acc: 0.87 - ETA: 1:36:43 - loss: 0.3838 - acc: 0.87 - ETA: 1:34:26 - loss: 0.3855 - acc: 0.87 - ETA: 1:32:35 - loss: 0.3844 - acc: 0.87 - ETA: 1:30:31 - loss: 0.3849 - acc: 0.87 - ETA: 1:28:32 - loss: 0.3835 - acc: 0.87 - ETA: 1:26:59 - loss: 0.3833 - acc: 0.87 - ETA: 1:25:16 - loss: 0.3821 - acc: 0.87 - ETA: 1:23:22 - loss: 0.3832 - acc: 0.87 - ETA: 1:22:03 - loss: 0.3849 - acc: 0.87 - ETA: 1:20:19 - loss: 0.3855 - acc: 0.87 - ETA: 1:18:32 - loss: 0.3862 - acc: 0.87 - ETA: 1:17:25 - loss: 0.3860 - acc: 0.87 - ETA: 1:16:04 - loss: 0.3865 - acc: 0.87 - ETA: 1:14:10 - loss: 0.3874 - acc: 0.86 - ETA: 1:12:18 - loss: 0.3869 - acc: 0.86 - ETA: 1:10:42 - loss: 0.3863 - acc: 0.87 - ETA: 1:09:47 - loss: 0.3861 - acc: 0.87 - ETA: 1:07:56 - loss: 0.3867 - acc: 0.87 - ETA: 1:06:15 - loss: 0.3866 - acc: 0.87 - ETA: 1:05:01 - loss: 0.3872 - acc: 0.86 - ETA: 1:03:55 - loss: 0.3868 - acc: 0.86 - ETA: 1:02:27 - loss: 0.3875 - acc: 0.86 - ETA: 1:01:06 - loss: 0.3887 - acc: 0.86 - ETA: 59:49 - loss: 0.3879 - acc: 0.8694 - ETA: 58:23 - loss: 0.3878 - acc: 0.86 - ETA: 56:44 - loss: 0.3882 - acc: 0.86 - ETA: 54:55 - loss: 0.3878 - acc: 0.86 - ETA: 53:06 - loss: 0.3881 - acc: 0.86 - ETA: 51:27 - loss: 0.3886 - acc: 0.86 - ETA: 49:52 - loss: 0.3877 - acc: 0.86 - ETA: 48:12 - loss: 0.3879 - acc: 0.86 - ETA: 46:28 - loss: 0.3882 - acc: 0.86 - ETA: 44:40 - loss: 0.3884 - acc: 0.86 - ETA: 42:58 - loss: 0.3875 - acc: 0.86 - ETA: 41:23 - loss: 0.3880 - acc: 0.86 - ETA: 40:17 - loss: 0.3878 - acc: 0.86 - ETA: 39:13 - loss: 0.3875 - acc: 0.86 - ETA: 38:10 - loss: 0.3876 - acc: 0.86 - ETA: 36:58 - loss: 0.3873 - acc: 0.86 - ETA: 35:42 - loss: 0.3881 - acc: 0.86 - ETA: 34:20 - loss: 0.3876 - acc: 0.86 - ETA: 32:52 - loss: 0.3875 - acc: 0.86 - ETA: 31:16 - loss: 0.3877 - acc: 0.86 - ETA: 29:33 - loss: 0.3872 - acc: 0.86 - ETA: 27:56 - loss: 0.3870 - acc: 0.86 - ETA: 26:08 - loss: 0.3871 - acc: 0.86 - ETA: 24:20 - loss: 0.3873 - acc: 0.86 - ETA: 22:28 - loss: 0.3877 - acc: 0.86 - ETA: 20:34 - loss: 0.3877 - acc: 0.86 - ETA: 18:40 - loss: 0.3876 - acc: 0.86 - ETA: 16:46 - loss: 0.3876 - acc: 0.86 - ETA: 14:50 - loss: 0.3875 - acc: 0.86 - ETA: 12:51 - loss: 0.3877 - acc: 0.86 - ETA: 10:47 - loss: 0.3878 - acc: 0.86 - ETA: 8:40 - loss: 0.3879 - acc: 0.8694 - ETA: 6:34 - loss: 0.3876 - acc: 0.869 - ETA: 4:24 - loss: 0.3880 - acc: 0.869 - ETA: 2:12 - loss: 0.3879 - acc: 0.869 - 9762s 139ms/step - loss: 0.3880 - acc: 0.8694 - val_loss: 0.4530 - val_acc: 0.8347\n",
      "Epoch 8/8\n",
      " 1000/70000 [..............................] - ETA: 3:17:20 - loss: 0.3844 - acc: 0.8710"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 8, batch_size=1000, verbose=1,validation_data=(X_test, y_test))\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1,9))\n",
    "train_acc_1  = history.history['acc']\n",
    "val_acc_1    = history.history['val_acc']\n",
    "vy_1 = history.history['val_loss']\n",
    "ty_1 = history.history['loss']\n",
    "plt_dynamic(x, vy_1, ty_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model 2- LSTM layer + Dropout (adam optimizer)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate and/or pad input sequences\n",
    "max_review_length = 1024\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab.keys())+1, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Dropout(0.9))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 20, batch_size=128, verbose=1,validation_data=(X_test, y_test))\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1,21))\n",
    "train_acc_1  = history.history['acc']\n",
    "val_acc_1    = history.history['val_acc']\n",
    "vy_1 = history.history['val_loss']\n",
    "ty_1 = history.history['loss']\n",
    "plt_dynamic(x, vy_1, ty_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model 3- LSTM  2 layer + Dropout (adam optimizer)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate and/or pad input sequences\n",
    "max_review_length = 1024\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab.keys())+1, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Dropout(0.9))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(LSTM(70))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 20, batch_size=128, verbose=1,validation_data=(X_test, y_test))\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1,21))\n",
    "train_acc_1  = history.history['acc']\n",
    "val_acc_1    = history.history['val_acc']\n",
    "vy_1 = history.history['val_loss']\n",
    "ty_1 = history.history['loss']\n",
    "plt_dynamic(x, vy_1, ty_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "ptable = PrettyTable()\n",
    "accuracy=[91.94,91.36,91.65]\n",
    "impl=[\"Model1 Simple LSTM \", \"Model2 with one LSTM layer with dropout\",\"Model3 with 2  LSTM layers with dropout\" ]\n",
    "ptable.add_column(\"S.NO\",[1,2,3])\n",
    "ptable.add_column(\"Implementation\",impl)\n",
    "ptable.add_column(\" Accuracy of model\",accuracy)\n",
    "print(ptable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
